# 推荐系统实战

## 第一章 好的推荐系统

* 2011年的Recsys大会专门邀请了Pandora的研究人员对音乐推荐进行了演讲
* 《长尾理论》
* [AB测试](http://www.abtests.com/)
* 信任度--评论网站Epinion

### 评测推荐系统的方法

* 离线实验
* 在线实验
* 用户调查


## 第二章 利用用户的行为数据

* 学术界提出了三种协同过滤方法
 * 基于领域的方法
 * 隐语义模型
 * 基于图的随机游走算法
* 应用最广的算法为基于领域的方法
 * 基于用户的协同过滤方法
   给用户推荐和他兴趣相似的其他用户喜欢的物品
 * 基于物品的协同过滤方法
   给用户推荐和他喜欢的物品相类似的物品

* [MovieLens数据集](http://www.grouplens.org/node/73)

### 2.4 基于领域的算法

#### 2.4.1 基于用户的过滤算法

* 找到和目标用户兴趣相似的用户集合
* 找到这个集合中的用户喜欢，且目标用户没有听说过的物品推荐给目标用户

* 缺点：随着用户数目越来越大，计算用户兴趣相似度矩阵越来越困难，其运算时间复杂度和空间复杂度和用户增长近似于平方关系，其次，基于用户的协同过滤很难对推荐结果做出解释。
  
##### 计算用户的兴趣相似度

给定用户u,v, 令N(u)表示用户u曾经有过正反馈的物品集合，令N(v)表示用户v曾经有过的正反馈物品集合

* 通过Jaccard公式计算u和v的兴趣相似度

$$w^j_{uv} = \frac{\vert{N(u)\cap{N(v)}\vert}}{\vert{N(u)\cup{N(v)}}\vert}$$

* 通过余弦相似度计算

$$w^c_{uv} = \frac{\vert{N(u)\cap{N(v)}\vert}}{\vert{N(u)\vert\vert{N(v)}}\vert}$$

* e.g.

用户A对物品{a, b, d}有过行为，用户B对物品{a, c}有过行为

$$w^j_{uv} = \frac{\vert{\{a, b, d\}\cap{\{a, c\}}\vert}}{\vert{\{a, b, d\}\cup{\{a, c\}}}\vert} = \frac{1}{4}$$

$$w^c_{uv} = \frac{\vert{\{a, b, d\}\cap{\{a, c\}}\vert}}{\vert{\{a, b, d\}\vert\vert{\{a, c\}}}\vert} = \frac{1}{\sqrt{6}}$$

##### UserCF算法

给用户推荐和他兴趣最相似的K个用户喜欢的物品，下面是计算用户u对物品i感兴趣的程度\
简单来说就是将与用户u兴趣最相似的K个用户的相似度对物品i的兴趣的乘积求和，得到用户u对物品i的兴趣度的预测

$$p(u,i) = \sum_{v\in S(u,K)\cap N(i)}w_{uv}r_{vi}$$

$S(u,K)$: 包含用户u兴趣最接近的K个用户\
$N(i)$: 对物品i有过行为的用户集合\
$r_{uv}$: 代表用户v对物品i的兴趣

##### 用户相似度的改进

e.g.: 对于流行度不同的物品，在计算用户相似度时应提供不同的贡献。以图书为例，a,b两个用户同时购买《新华字典》, c,d两个用户同时购买《白夜行》，我们可以说c，d用户兴趣相似，但不能说a，b两个用户兴趣相似，因为《新华字典》大多数中国人小时候都买过。

##### User-IIF算法

惩罚流行度高的物品在计算用户相似度时的影响

$$w_{uv} = \frac{\sum_{i\in N(u)\cap N(v)}\frac{1}{\log1 + \vert N(i) \vert}}{\vert{N(u)\vert\vert{N(v)}}\vert}$$


#### 2.4.2 基于物品的协同过滤算法--ItemCF

**注**: ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。

e.g.:该算法认为，物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B

* 计算物品之间的 相似度
* 根据物品的相似度和用户的历史行为给用户生成推荐列表

$$w_{ij} = \frac{\vert N(i)\cap N(j)\vert}{\vert N(i)\vert}$$

$N(i)$: 喜欢物品i的用户
$\vert N(i)\vert$: 喜欢物品i的用户数

上述公式描述了喜欢物品i的用户中有多少同时喜欢物品j。但这种计算方法会带来一个问题，如果物品i是热门物品，很多人喜欢，那么$w_{ij}$就会很大，极端情况就是所有喜欢物品j的用户都喜欢物品i，$w_{ij}==1$.这会造成该算法推荐的物品和热门物品有很大的相似度。

为了避免这个问题，可以用下面的公式：

$$w_{ij} = \frac{\vert N(i)\cap N(j)\vert}{\sqrt{\vert N(i)\vert \vert N(j)\vert}}$$

进阶版
$$w_{ij} = \frac{\vert N(i)\cap N(j)\vert}{\vert N(i)\vert ^{1-\alpha} \vert N(j)\vert ^{\alpha}}$$

##### ItemCF算法

$$p(u,j) = \sum_{i\in S(j,K)\cap N(u)}w_{ji}r_{ui}$$

$S(j,K)$: 和物品j最相似的K个物品的几何
$r_{ui}$: 用户u对物品i的兴趣度(对于隐反馈数据集，如果用户u对物品i有过行为，即可零$r_{ui}=1$)


##### ItemCF-IUF算法

我们假设这样一个情况，一个书店老板为了开书店去当当网买了80万本书。根据ItemCF算法，这意味着80万本书两两之间产生了相似度，但是这各用户并不是出于自身的兴趣购买的图书。

所以在计算物品相似度时，应该根据用户的活跃度给予不同的权重，使得活跃度越高的用户贡献度越小。

$$w_{ij} = \frac{\sum_{i\in N(i)\cap N(j)}\frac{1}{\log1 + \vert N(u) \vert}}{\sqrt{\vert{N(i)\vert\vert{N(j)}}\vert}}$$

对于过于活跃的用户我们直接忽略他的兴趣列表。

##### 物品相似度归一化

Karypis在研究中心发现如果将ItemCF的相似度矩阵按最大值归一化，可以提高推荐的准确率。(Evaluation of Item-based Top-N Recommendation Algorithms)

$$w^{'}_{ij} = \frac{w_{ij}}{\max_{j} w_{ij}}$$


**总结**

* UserCF算法给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品。UserCF的推荐更加社会化，反映了用户所在的小型兴趣群体中物品的热门程度。
* ItemCF给用户推荐那些和他之前喜欢的物品类似的物品。ItemCF推荐更加个性化，反映了用户自己的兴趣传承。


### 2.5 隐语义模型-LFM(laten factor model)

LFM通过如下公司计算用户u对物品i的兴趣

$$Preference(u,i) = r_{ui} = p^{T}_{u}q_{i} = \sum^F_{f=1}p_{u,k}q_{i,k}$$

$p_{u,k}$: 用户u的兴趣和第k个隐类的关系
$q_{i,k}$: 第k个隐类和物品i之间的关系

因为隐性反馈数据集只有正样本(用户喜欢什么物品)，而没有负样本(用户对什么物品不感兴趣)，所以，我们需要给每个用户生成负样本

生成负样本应遵循以下原则

* 对于每个用户，要保证正负样本的平衡(数目相似)
* 对每个用户采样负样本时，要选取那些很热门的，而用户却没有行为的物品

解释：一般认为，很热门而用户却没有行为更加代表用户对这个物品不感兴趣。因为对于冷门的物品，用户可能是压根没在网站中发现这个物品，所以谈不上是否感兴趣

我们通过优化如下损失函数来找到最合适的参数p和q

$$C=\sum_{(u,i)\in K}(r_{ui} - \hat r_{ui})^2 = \sum_{(u,i)\in K}(r_{ui} - \sum^K_{k=1}p_{u,k}q_{i,k})^2 + \lambda \Vert p_u\Vert ^2 + \lambda \Vert q_i\Vert ^2$$

使用随机梯度方法更新参数$p_{uk}$ $q_{ik}$

$$\frac{\partial C}{\partial p_{uk}} = -2q_{ik} + 2\lambda p_{uk}\quad
\frac{\partial C}{\partial q_{ik}} = -2p_{uk} + 2\lambda q_{ik}$$

$$p_{uk} = p_{uk} + \alpha(q_{ik} - \lambda p_{uk})
\quad
q_{ik} = q_{ik} + \alpha(p_{uk} - \lambda q_{ik})$$

**在LFM中，重要的参数有4个**
* 隐特征的个数F
* 学习速率$\alpha$
* 正则化参数$\lambda$
* 负样本/正样本比例ratio

### 2.6 基于图的模型


## 第三章 推荐系统冷启动问题

* **冷启动问题**
如何在没有大量用户数据的情况下设计个性化推荐新系统并且让用户对推荐结果满意从而愿意使用推荐系统

* **冷启动问题主要分为三类**
  * 用户冷启动: 如何给新用户做个性化推荐
  * 物品冷启动: 如何将新物品推荐给可能对它感兴趣的用户
  * 系统冷启动: 如何在一个新开发的网站上设计推荐系统

### 用户冷启动方案

#### 提供非个性化推荐

针对新用户，我们可以给用户推荐热门排行榜，然后等到用户数据收集到一定的时候，再切换为个性化推荐。

#### 利用用户注册信息

基于注册信息的个性化推荐流程如下:
* 获取用户注册信息
* 根据用户的注册信息对用户分类
* 给用户推荐他所属分类中用户喜欢的物品

用户注册信息主要分3类
* 人口统计学特征: 包括用户的年龄、性别、职业、民族、学历和居住地
* 用户兴趣的描述：有一些网站会让用户用文字描述他们的兴趣
* 从其他网站导入的用户站外行为数据

基于用户注册信息的推荐算法其核心问题是计算具有特征$f$的用户对于物品$i$的喜好程度$p(f,i)$

基本算法
$$p(f,i) = \vert N(i)\cap U(f)\vert$$

$N(i)$: 喜好物品$i$的用户
$U(f)$: 具有特征$f$的用户

问题：这种算法会导致热门物品会在各种用户中都具有比较高的权重

改进算法

$$p(f,i) = \frac{\vert N(i)\cap U(f)\vert}{\vert N(i)\vert + \alpha}$$

$\alpha$解释：参数$\alpha$目的是解决数据稀疏的问题。假定有一个物品只被一个用户喜欢过，而这个用户刚好就有特征$f$，那么就有$p(f,i)=1$.但是这种情况并没有统计意义。因此我们为分母加上一个比较大的数，避免这样的物品产生比较大的权重。

#### 选择合适的物品启动用户的兴趣

在新用户第一次访问推荐系统时，给用户提供一些物品，让用户反馈他们对这些物品的兴趣，然后根据用户反馈给提供个性化推荐。

一般来说，能够用来启动用户兴趣的物品需要具有以下特点

* 比较热门：用户必须了解这个物品
* 具有代表性和区分性：这要求物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性
* 启动物品集合需要多样性：因为用户兴趣的可能性非常多，所以我们需要具有很高覆盖率的物品，这些物品能覆盖几乎所有主流的用户兴趣

问题：如何设计一个选择启动物品集合的系统

Nadav Golbandi的[论文](http://research.yahoo.com/pub/3502)提出用用户对物品评分的方差度量这群用户兴趣的一致程度。

计算物品$i$的区分度$D(i)$

$$D(i) = \sigma_{u\in N^{+}(i)} + \sigma_{u\in N^-(i)} + \sigma_{u\in \bar N(i)}$$

$N^+(i)$: 喜欢物品$i$的用户集合\
$N^-(i)$: 不喜欢物品$i$的用户集合\
$\bar N(i)$: 没有对物品$i$评分的用户集合\
$\sigma_{u\in N^{+}(i)}$: 喜欢物品$i$的用户对其他物品评分的方差\
$\sigma_{u\in N^-(i)}$: 不喜欢物品$i$的用户对其他物品评分的方差\
$\sigma_{u\in \bar N(i)}$: 没有对物品$i$评分的用户对其他物品评分的方差

### 3.4 利用物品的内容信息

物品冷启动需要解决的问题是如何将新加入的物品推荐给对它感兴趣的用户

#### 内容过滤算法--ContentItemKNN

提取物品内容信息的关键词，将其表示为向量

对于物品d，它的内容表示成一个关键词向量如下:

$$d = \{(e_1, w_1), (e_2, w_2), ...\}$$

$e_i$: 关键词
$w_i$: 关键词对应的权重

对于文本物品，可以用信息检索领域著名的TF-IDF公式计算词的权重

$$w_i = \frac{TF(e_i)}{\log DF(e_i)}$$

然后计算余弦相似度

$$w_{ij} = \frac{d_i\cdot d_j}{\sqrt{\Vert d_{i}\Vert d_j}}$$

### 3.5 发挥专家的作用
很多推荐系统在建立时，既没有用户的行为数据，也没有充足的物品内容信息来计算准确的物品相似度。那么为了在推荐系统建立时就让用户得到比较好的体验，很多系统都利用专家进行标注。

代表系统: 个性化网络电台Pandora 电影推荐网站Jinni 